{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from keras_tuner import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import relative_accuracy as ra\n",
    "from statistics import mean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all Inputs and Output Data\n",
    "\n",
    "# 5 mins (1 step ahead)\n",
    "Deep_train_5   = np.load(\"Deep_train_5.npz\")['x'] \n",
    "Output_train_5 = np.load(\"Deep_train_5.npz\")['y']\n",
    "\n",
    "Deep_test_5   = np.load(\"Deep_test_5.npz\")['x'] \n",
    "Output_test_5 = np.load(\"Deep_test_5.npz\")['y'] \n",
    "\n",
    "# 15 mins (3 steps ahead)\n",
    "Deep_train_15   = np.load(\"Deep_train_15.npz\")['x'] \n",
    "Output_train_15 = np.load(\"Deep_train_15.npz\")['y']\n",
    "\n",
    "Deep_test_15   = np.load(\"Deep_test_15.npz\")['x'] \n",
    "Output_test_15 = np.load(\"Deep_test_15.npz\")['y']\n",
    "\n",
    "# 30 mins (6 steps ahead)\n",
    "Deep_train_30   = np.load(\"Deep_train_30.npz\")['x'] \n",
    "Output_train_30 = np.load(\"Deep_train_30.npz\")['y']\n",
    "\n",
    "Deep_test_30   = np.load(\"Deep_test_30.npz\")['x'] \n",
    "Output_test_30 = np.load(\"Deep_test_30.npz\")['y']\n",
    "\n",
    "# 60 mins (12 steps ahead)\n",
    "Deep_train_60   = np.load(\"Deep_train_60.npz\")['x'] \n",
    "Output_train_60 = np.load(\"Deep_train_60.npz\")['y']\n",
    "\n",
    "Deep_test_60   = np.load(\"Deep_test_60.npz\")['x'] \n",
    "Output_test_60 = np.load(\"Deep_test_60.npz\")['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wide Week Data\n",
    "Xtrain = joblib.load(\"002weeks_train.save\") \n",
    "Xtest = joblib.load(\"002weeks_test.save\") \n",
    "\n",
    "# Wide Day Data\n",
    "Xtrain_day = joblib.load(\"002days_train.save\") \n",
    "Xtest_day = joblib.load(\"002days_test.save\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 mins\n",
    "# Delete first 15 samples\n",
    "Wide_train_5 = np.delete(Xtrain, np.s_[0:15], 0)\n",
    "Wide_test_5 = np.delete(Xtest, np.s_[0:15], 0)\n",
    "\n",
    "Wide_train_5_day = np.delete(Xtrain_day, np.s_[0:15], 0)\n",
    "Wide_test_5_day = np.delete(Xtest_day, np.s_[0:15], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 mins\n",
    "# Delete first 17 samples\n",
    "Wide_train_15 = np.delete(Xtrain, np.s_[0:17], 0)\n",
    "Wide_test_15 = np.delete(Xtest, np.s_[0:17], 0)\n",
    "\n",
    "Wide_train_15_day = np.delete(Xtrain_day, np.s_[0:17], 0)\n",
    "Wide_test_15_day = np.delete(Xtest_day, np.s_[0:17], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 mins\n",
    "# Delete first 20 samples\n",
    "Wide_train_30 = np.delete(Xtrain, np.s_[0:20], 0)\n",
    "Wide_test_30 = np.delete(Xtest, np.s_[0:20], 0)\n",
    "\n",
    "Wide_train_30_day = np.delete(Xtrain_day, np.s_[0:20], 0)\n",
    "Wide_test_30_day = np.delete(Xtest_day, np.s_[0:20], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60 mins\n",
    "# Delete first 27 samples\n",
    "Wide_train_60 = np.delete(Xtrain, np.s_[0:26], 0)\n",
    "Wide_test_60 = np.delete(Xtest, np.s_[0:26], 0)\n",
    "\n",
    "Wide_train_60_day = np.delete(Xtrain_day, np.s_[0:26], 0)\n",
    "Wide_test_60_day = np.delete(Xtest_day, np.s_[0:26], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_filename = \"scaler.save\"\n",
    "scaler = joblib.load(scaler_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test      = pd.read_csv('01test_scaled.csv', index_col=None, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to split the input sequences into subsequences that can be processed by the CNN model. Here, each spatio-temporal sample can be split into three sub-samples, each with five time steps. The CNN can interpret each subsequence of five time steps and provide a time series of interpretations of the subsequences to the LSTM model to process as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "n_features = 6              # No of loop detectors\n",
    "n_seq = 3                    # Subsequences\n",
    "n_steps = 5                  # time-step per subsequence\n",
    "val_percent = 0.07567        # 2 weeks\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "Xt5 = Deep_train_5.reshape((Deep_train_5.shape[0], n_seq, n_steps, n_features))\n",
    "yt5 = Output_train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "Xv5 = Deep_test_5.reshape((Deep_test_5.shape[0], n_seq, n_steps, n_features))\n",
    "yv5 = Output_test_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "Xt15 = Deep_train_15.reshape((Deep_train_15.shape[0], n_seq, n_steps, n_features))\n",
    "yt15 = Output_train_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "Xv15 = Deep_test_15.reshape((Deep_test_15.shape[0], n_seq, n_steps, n_features))\n",
    "yv15 = Output_test_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "Xt30 = Deep_train_30.reshape((Deep_train_30.shape[0], n_seq, n_steps, n_features))\n",
    "yt30 = Output_train_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "Xv30 = Deep_test_30.reshape((Deep_test_30.shape[0], n_seq, n_steps, n_features))\n",
    "yv30 = Output_test_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 60 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "Xt60 = Deep_train_60.reshape((Deep_train_60.shape[0], n_seq, n_steps, n_features))\n",
    "yt60 = Output_train_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "Xv60 = Deep_test_60.reshape((Deep_test_60.shape[0], n_seq, n_steps, n_features))\n",
    "yv60 = Output_test_60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the Data for Conv2D layer\n",
    "\n",
    "For Conv2D, there is a need to add one more dimension to show we're dealing with 1 channel (since technically the images are in black and white, only showing values from 0-max flow on a single channel).\n",
    "\n",
    "Conv1D - strides in 1 dimension\n",
    "Conv2D - strides in 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define no_of_channels\n",
    "n_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "Xt5  =  Xt5.reshape(Xt5.shape[0], n_seq, n_steps, n_features, n_channels)\n",
    "Xt15 =  Xt15.reshape(Xt15.shape[0], n_seq, n_steps, n_features, n_channels)\n",
    "Xt30 =  Xt30.reshape(Xt30.shape[0], n_seq, n_steps, n_features, n_channels)\n",
    "Xt60 =  Xt60.reshape(Xt60.shape[0], n_seq, n_steps, n_features, n_channels)\n",
    "\n",
    "# Validation data\n",
    "Xv5  =  Xv5.reshape(Xv5.shape[0], n_seq, n_steps, n_features, n_channels)\n",
    "Xv15 =  Xv15.reshape(Xv15.shape[0], n_seq, n_steps, n_features, n_channels)\n",
    "Xv30 =  Xv30.reshape(Xv30.shape[0], n_seq, n_steps, n_features, n_channels)\n",
    "Xv60 =  Xv60.reshape(Xv60.shape[0], n_seq, n_steps, n_features, n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wide_train_5 = np.expand_dims(Wide_train_5, 1)\n",
    "Wide_train_15 = np.expand_dims(Wide_train_15, 1)\n",
    "Wide_train_30 = np.expand_dims(Wide_train_30, 1)\n",
    "Wide_train_60 = np.expand_dims(Wide_train_60, 1)\n",
    "\n",
    "Wide_test_5 = np.expand_dims(Wide_test_5, 1)\n",
    "Wide_test_15 = np.expand_dims(Wide_test_15, 1)\n",
    "Wide_test_30 = np.expand_dims(Wide_test_30, 1)\n",
    "Wide_test_60 = np.expand_dims(Wide_test_60, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wide_train_5_day = np.expand_dims(Wide_train_5_day, 1)\n",
    "Wide_train_15_day = np.expand_dims(Wide_train_15_day, 1)\n",
    "Wide_train_30_day = np.expand_dims(Wide_train_30_day, 1)\n",
    "Wide_train_60_day = np.expand_dims(Wide_train_60_day, 1)\n",
    "\n",
    "Wide_test_5_day = np.expand_dims(Wide_test_5_day, 1)\n",
    "Wide_test_15_day = np.expand_dims(Wide_test_15_day, 1)\n",
    "Wide_test_30_day = np.expand_dims(Wide_test_30_day, 1)\n",
    "Wide_test_60_day = np.expand_dims(Wide_test_60_day, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wt5  = Wide_train_5\n",
    "Wt15 = Wide_train_15\n",
    "Wt30 = Wide_train_30\n",
    "Wt60 = Wide_train_60\n",
    "\n",
    "Wv5  = Wide_test_5\n",
    "Wv15 = Wide_test_15\n",
    "Wv30 = Wide_test_30\n",
    "Wv60 = Wide_test_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wt5x  = Wide_train_5_day\n",
    "Wt15x = Wide_train_15_day\n",
    "Wt30x = Wide_train_30_day\n",
    "Wt60x = Wide_train_60_day\n",
    "\n",
    "Wv5x  = Wide_test_5_day\n",
    "Wv15x = Wide_test_15_day\n",
    "Wv30x = Wide_test_30_day\n",
    "Wv60x = Wide_test_60_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    patience = 5, \n",
    "    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49233, 1, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wide_train_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 6, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt5.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30 mins ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_30(hp):\n",
    "    # Inputs\n",
    "    channel_Wide = keras.layers.Input(shape=Wide_train_30.shape[1:], name=\"wide_week\")\n",
    "    channel_Widex = keras.layers.Input(shape=Wide_train_30_day.shape[1:], name=\"wide_day\")\n",
    "    channel_Deep = keras.layers.Input(shape=Xt30.shape[1:], name=\"deep_input\")\n",
    "    \n",
    "    # Wide Model\n",
    "    Wide_30 = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(units=hp.Int(\"wide_week_LSTM\", min_value=1, max_value=100, step=1), \n",
    "                                activation='relu'))(channel_Wide)\n",
    "    \n",
    "    Wide_30x = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(units=hp.Int(\"wide_day_LSTM\", min_value=1, max_value=100, step=1), \n",
    "                                activation='relu'))(channel_Widex)\n",
    "    \n",
    "    # Deep Model\n",
    "    # CNN \n",
    "    CNN_30a = keras.layers.TimeDistributed(\n",
    "        keras.layers.Conv2D(filters=hp.Int(\"filters\", min_value=32, max_value=512, step=32),\n",
    "                            kernel_size=hp.Choice(\"kernel_size\", [2, 3]), activation='relu'))(channel_Deep)\n",
    "    CNN_30b = keras.layers.TimeDistributed(\n",
    "        keras.layers.Conv2D(filters=hp.Int(\"filters\", min_value=32, max_value=512, step=32),\n",
    "                            kernel_size=hp.Choice(\"kernel_size\", [2, 3]), activation='relu'))(CNN_30a)\n",
    "    flatten_30 = keras.layers.TimeDistributed(keras.layers.Flatten())(CNN_30b)\n",
    "    # LSTM          \n",
    "    LSTM_30a = keras.layers.LSTM(units=hp.Int(\"units_LSTM\", min_value=1, max_value=100, step=1), \n",
    "                                activation='relu', return_sequences=True)(flatten_30)\n",
    "    LSTM_30b = keras.layers.LSTM(units=hp.Int(\"units_LSTM\", min_value=1, max_value=100, step=1), \n",
    "                                activation='relu', return_sequences=True)(LSTM_30a)\n",
    "    Att_30 = SeqSelfAttention(attention_activation='tanh')(LSTM_30b)\n",
    "    Reshaped_30 = keras.layers.Flatten()(Att_30)\n",
    "    \n",
    "    # Concatenation \n",
    "    concat = keras.layers.concatenate([Wide_30, Wide_30x, Reshaped_30])\n",
    "    \n",
    "    # Output\n",
    "    output = keras.layers.Dense(n_features, name= \"output\")(concat)\n",
    "    \n",
    "    # Model\n",
    "    model_30 = keras.Model(inputs=[channel_Wide, channel_Widex, channel_Deep], outputs=[output])\n",
    "\n",
    "    # Compile\n",
    "    model_30.compile(optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])), \n",
    "        loss='mse',metrics=['MeanAbsoluteError','RootMeanSquaredError','MeanAbsolutePercentageError'])\n",
    "                    \n",
    "    return model_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner30 = RandomSearch(\n",
    "    build_model_30,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=30,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=False,\n",
    "    directory=os.path.normpath('C:/RunsOak'),\n",
    "    project_name=\"8a-Conv-LSTM-30\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "wide_week_LSTM (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 100, 'step': 1, 'sampling': None}\n",
      "wide_day_LSTM (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 100, 'step': 1, 'sampling': None}\n",
      "filters (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "kernel_size (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3], 'ordered': True}\n",
      "units_LSTM (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 100, 'step': 1, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner30.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 16m 22s]\n",
      "val_loss: 0.002025944762863219\n",
      "\n",
      "Best val_loss So Far: 0.0020111437188461423\n",
      "Total elapsed time: 20h 47m 44s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner30.search((Wt30, Wt30x, Xt30), yt30, epochs=200,\n",
    "            validation_split = val_percent,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in C:\\RunsOak\\8a-Conv-LSTM-30\n",
      "Showing 1 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "wide_week_LSTM: 87\n",
      "wide_day_LSTM: 66\n",
      "filters: 480\n",
      "kernel_size: 2\n",
      "units_LSTM: 75\n",
      "learning_rate: 0.001\n",
      "Score: 0.0020111437188461423\n"
     ]
    }
   ],
   "source": [
    "tuner30.results_summary(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp30 = tuner30.get_best_hyperparameters()[0]\n",
    "model30 = tuner30.hypermodel.build(best_hp30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8a-Conv_LSTM-30']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_filename = \"8a-Conv_LSTM-30\"\n",
    "joblib.dump(best_hp30, scaler_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 3, 5, 6, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 3, 4, 5, 480  2400       ['deep_input[0][0]']             \n",
      " buted)                         )                                                                 \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, 3, 3, 4, 480  922080     ['time_distributed_3[0][0]']     \n",
      " buted)                         )                                                                 \n",
      "                                                                                                  \n",
      " time_distributed_5 (TimeDistri  (None, 3, 5760)     0           ['time_distributed_4[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  (None, 3, 75)        1750800     ['time_distributed_5[0][0]']     \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  (None, 3, 75)        45300       ['lstm_6[0][0]']                 \n",
      "                                                                                                  \n",
      " wide_week (InputLayer)         [(None, 1, 14)]      0           []                               \n",
      "                                                                                                  \n",
      " wide_day (InputLayer)          [(None, 1, 14)]      0           []                               \n",
      "                                                                                                  \n",
      " seq_self_attention_1 (SeqSelfA  (None, 3, 75)       4865        ['lstm_7[0][0]']                 \n",
      " ttention)                                                                                        \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 174)         70992       ['wide_week[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 132)         42768       ['wide_day[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 225)          0           ['seq_self_attention_1[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 531)          0           ['bidirectional_2[0][0]',        \n",
      "                                                                  'bidirectional_3[0][0]',        \n",
      "                                                                  'flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            532         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,839,737\n",
      "Trainable params: 2,839,737\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model30.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_60(hp):\n",
    "    # Inputs\n",
    "    channel_Wide = keras.layers.Input(shape=Wide_train_60.shape[1:], name=\"wide_week\")\n",
    "    channel_Widex = keras.layers.Input(shape=Wide_train_60_day.shape[1:], name=\"wide_day\")\n",
    "    channel_Deep = keras.layers.Input(shape=Xt60.shape[1:], name=\"deep_input\")\n",
    "    \n",
    "    # Wide Model\n",
    "    Wide_60 = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(units=hp.Int(\"wide_week_LSTM\", min_value=1, max_value=100, step=1), \n",
    "                                activation='relu'))(channel_Wide)\n",
    "    \n",
    "    Wide_60x = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(units=hp.Int(\"wide_day_LSTM\", min_value=1, max_value=100, step=1), \n",
    "                                activation='relu'))(channel_Widex)\n",
    "    \n",
    "    # Deep Model\n",
    "    # CNN \n",
    "    CNN_60a = keras.layers.TimeDistributed(\n",
    "        keras.layers.Conv2D(filters=hp.Int(\"filters\", min_value=32, max_value=512, step=32),\n",
    "                            kernel_size=hp.Choice(\"kernel_size\", [2, 3]), activation='relu'))(channel_Deep)\n",
    "    CNN_60b = keras.layers.TimeDistributed(\n",
    "        keras.layers.Conv2D(filters=hp.Int(\"filters\", min_value=32, max_value=512, step=32),\n",
    "                            kernel_size=hp.Choice(\"kernel_size\", [2, 3]), activation='relu'))(CNN_60a)\n",
    "    flatten_60 = keras.layers.TimeDistributed(keras.layers.Flatten())(CNN_60b)\n",
    "    # LSTM          \n",
    "    LSTM_60a = keras.layers.LSTM(units=hp.Int(\"units_LSTM\", min_value=1, max_value=100, step=1), \n",
    "                                activation='relu', return_sequences=True)(flatten_60)\n",
    "    LSTM_60b = keras.layers.LSTM(units=hp.Int(\"units_LSTM\", min_value=1, max_value=100, step=1), \n",
    "                                activation='relu', return_sequences=True)(LSTM_60a)\n",
    "    Att_60 = SeqSelfAttention(attention_activation='tanh')(LSTM_60b)\n",
    "    Reshaped_60 = keras.layers.Flatten()(Att_60)\n",
    "    \n",
    "    # Concatenation \n",
    "    concat = keras.layers.concatenate([Wide_60, Wide_60x, Reshaped_60])\n",
    "    \n",
    "    # Output\n",
    "    output = keras.layers.Dense(n_features, name= \"output\")(concat)\n",
    "    \n",
    "    # Model\n",
    "    model_60 = keras.Model(inputs=[channel_Wide, channel_Widex, channel_Deep], outputs=[output])\n",
    "\n",
    "    # Compile\n",
    "    model_60.compile(optimizer=keras.optimizers.Adam(hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])), \n",
    "        loss='mse',metrics=['MeanAbsoluteError','RootMeanSquaredError','MeanAbsolutePercentageError'])\n",
    "                    \n",
    "    return model_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner60 = RandomSearch(\n",
    "    build_model_60,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=30,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=False,\n",
    "    directory=os.path.normpath('C:/RunsOak'),\n",
    "    project_name=\"8a-Conv-LSTM-60\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "wide_week_LSTM (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 100, 'step': 1, 'sampling': None}\n",
      "wide_day_LSTM (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 100, 'step': 1, 'sampling': None}\n",
      "filters (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "kernel_size (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3], 'ordered': True}\n",
      "units_LSTM (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 100, 'step': 1, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner60.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [01h 22m 18s]\n",
      "val_loss: 0.0022131188306957483\n",
      "\n",
      "Best val_loss So Far: 0.0021462483564391732\n",
      "Total elapsed time: 01h 13m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner60.search((Wt60, Wt60x, Xt60), yt60, epochs=200,\n",
    "            validation_split = val_percent,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in C:\\RunsOak\\8a-Conv-LSTM-60\n",
      "Showing 1 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "wide_week_LSTM: 77\n",
      "wide_day_LSTM: 61\n",
      "filters: 256\n",
      "kernel_size: 3\n",
      "units_LSTM: 63\n",
      "learning_rate: 0.001\n",
      "Score: 0.0021462483564391732\n"
     ]
    }
   ],
   "source": [
    "tuner60.results_summary(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp60 = tuner60.get_best_hyperparameters()[0]\n",
    "model60 = tuner60.hypermodel.build(best_hp60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Best_HP/8a-Conv_LSTM-60']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_filename = \"Best_HP/8a-Conv_LSTM-60\"\n",
    "joblib.dump(best_hp60, scaler_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 3, 5, 6, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 3, 3, 4, 256  2560       ['deep_input[0][0]']             \n",
      " buted)                         )                                                                 \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, 3, 1, 2, 256  590080     ['time_distributed_3[0][0]']     \n",
      " buted)                         )                                                                 \n",
      "                                                                                                  \n",
      " time_distributed_5 (TimeDistri  (None, 3, 512)      0           ['time_distributed_4[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  (None, 3, 63)        145152      ['time_distributed_5[0][0]']     \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  (None, 3, 63)        32004       ['lstm_6[0][0]']                 \n",
      "                                                                                                  \n",
      " wide_week (InputLayer)         [(None, 1, 14)]      0           []                               \n",
      "                                                                                                  \n",
      " wide_day (InputLayer)          [(None, 1, 14)]      0           []                               \n",
      "                                                                                                  \n",
      " seq_self_attention_1 (SeqSelfA  (None, 3, 63)       4097        ['lstm_7[0][0]']                 \n",
      " ttention)                                                                                        \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 154)         56672       ['wide_week[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 122)         37088       ['wide_day[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 189)          0           ['seq_self_attention_1[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 465)          0           ['bidirectional_2[0][0]',        \n",
      "                                                                  'bidirectional_3[0][0]',        \n",
      "                                                                  'flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            466         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 868,119\n",
      "Trainable params: 868,119\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model60.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
